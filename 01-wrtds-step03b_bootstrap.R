## ---------------------------------------------- ##
        # WRTDS Centralized Workflow
## ---------------------------------------------- ##
# WRTDS = Weighted Regressions on Time, Discharge, and Season
## Nick J Lyon

## ---------------------------------------------- ##
                # Housekeeping ----
## ---------------------------------------------- ##
# Load libraries
# install.packages("librarian")
librarian::shelf(tidyverse, googledrive, lubridate, EGRET, EGRETci, lter/HERON, supportR)

# Clear environment
rm(list = ls())

# If working on server, need to specify correct path
(path <- scicomptools::wd_loc(local = FALSE, remote_path = file.path('/', "home", "shares", "lter-si", "WRTDS")))

# Make sure necessary folders exist
dir.create(path = file.path(path, "WRTDS Inputs"), showWarnings = F)
dir.create(path = file.path(path, "WRTDS Temporary Files"), showWarnings = F)
dir.create(path = file.path(path, "WRTDS Bootstrap Diagnostic"), showWarnings = F)
dir.create(path = file.path(path, "WRTDS Bootstrap Outputs"), showWarnings = F)

# Identify CSVs generated by 'step-2' script
input_ids <- googledrive::drive_ls(googledrive::as_id("https://drive.google.com/drive/u/0/folders/1QEofxLdbWWLwkOTzNRhI6aorg7-2S3JE"))

# Download them locally
for(k in 1:nrow(input_ids)){
  
  # Processing message
  message("Downloading file '", input_ids$name[k], "'")
  
  # Download files
  input_ids %>%
    # Filter to desired file
    dplyr::filter(name == input_ids$name[k]) %>%
    # Download that file!
    googledrive::drive_download(file = as_id(.), overwrite = T,
                                path = file.path(path, "WRTDS Inputs", input_ids$name[k]))
}

# Read in CSVs generated by 'step-2' script
discharge <- read.csv(file.path(path, "WRTDS Inputs", "WRTDS-input_discharge.csv"))
chemistry <- read.csv(file.path(path, "WRTDS Inputs", "WRTDS-input_chemistry.csv"))
information <- read.csv(file.path(path, "WRTDS Inputs", "WRTDS-input_information.csv"))

# Identify rivers that make it through the regular workflow
good_rivers <- data.frame("file" = dir(path = file.path(path, "WRTDS Loop Diagnostic"))) %>%
  # Drop the file suffix part of the file name 
  dplyr::mutate(river = gsub(pattern = "\\_Loop\\_Diagnostic.csv", replacement = "", x = file)) %>%
  # Pull out just the river
  dplyr::pull(river)

## ---------------------------------------------- ##
              # Bootstrap Workflow ----
## ---------------------------------------------- ##

# Re-identify rivers that have special period of analysis requirements
pa5_5 <- c(
  # EGRET::setPA(eList = egret_list[_out], paStart = 5, paLong = 5)
  "NWT__MARTINELLI_DSi", "NWT__MARTINELLI_NH4", 
  "NWT__MARTINELLI_NOx", "NWT__MARTINELLI_P")

pa5_3 <- c(
  # EGRET::setPA(eList = egret_list[_out], paStart = 5, paLong = 3)
  "NWT__SADDLE STREAM 007_DSi", "NWT__SADDLE STREAM 007_NH4", 
  "NWT__SADDLE STREAM 007_NOx", "NWT__SADDLE STREAM 007_P")

# Identify potential rivers to run through the bootstrap workflow
potential_boots <- data.frame("x" = unique(good_rivers)) %>%
  # Identify LTER
  tidyr::separate(x, sep = "__", into = c("site", "river_name"), remove = F) %>%
  # Drop any LTERs we aren't interested in
  ## Virtually all Finnish sites threw an error when attempted
  ## KRR sites crashed R without a specific warning message
  dplyr::filter(!site %in% c("Finnish Environmental Institute", "KRR")) %>%
  # Pull the full river names back out!
  dplyr::pull(x)

# Identify completed bootstrap rivers
done_boots <- data.frame("file" = dir(path = file.path(path, "WRTDS Bootstrap Diagnostic"))) %>%
  # Drop the file suffix part of the file name 
  dplyr::mutate(river = gsub(pattern = "\\_Boot\\_Loop\\_Diagnostic.csv", replacement = "", x = file)) %>%
  # Pull out just that column
  dplyr::pull(river)

# Set of problem rivers to drop from the loop
bad_boot_rivers <- c(
  # R crashes running these sites:
  "ARC__Imnavait Weir_DSi", "Krycklan__Site 10_DSi", "Krycklan__Site 13_DSi",
  "Krycklan__Site 2_DSi", "Krycklan__Site 9_DSi", "LMP__LMP73_P", "LUQ__Q2_DSi",
  "LUQ__Q3_DSi", "LUQ__QS_DSi", "MCM__Green Creek at F9_DSi", 
  "USGS__Brazos River near Rosharon_NH4",
  "USGS__CANAJOHARIE CREEK_P", # R crashes here too but seems to work for first 10 bootstraps...
  "USGS__Dismal River_NH4", # Same deal (crashes) but gets through 49 bootstraps...
  "USGS__EAGLE RIVER AT AVON_NH4", "USGS__EAGLE RIVER AT RED CLIFF_NH4",
  "USGS__EAGLE RIVER NEAR MINTURN_NH4", "USGS__GORE CREEK AT MOUTH_NH4",
  "USGS__GORE CREEK UPPER STATION_NH4", "USGS__GREEN RIVER_NH4",
  "USGS__LITTLE RIVER_NH4", "USGS__MERCED R_NH4","USGS__YAMPA RIVER AT DEERLODGE PARK_NH4",
  ## Pre-emptively moving some other sites here that are likely to crash R
  ## Will double check whether these fail once other streams are done
  "ARC__Imnavait Weir_NH4", "ARC__Imnavait Weir_NOx", "ARC__Imnavait Weir_P",
  "LUQ__Q2_NH4", "LUQ__Q2_NOx", "LUQ__Q2_P",
  "LUQ__Q3_NH4", "LUQ__Q3_NOx", "LUQ__Q3_P",
  "LUQ__QS_NH4", "LUQ__QS_NOx", "LUQ__QS_P",
  "MCM__Green Creek at F9_NH4", "MCM__Green Creek at F9_NOx", "MCM__Green Creek at F9_P",
  "USGS__Brazos River near Rosharon_NOx", "USGS__Brazos River near Rosharon_P", 
  "USGS__Dismal River_NOx", "USGS__Dismal River_P", "USGS__EAGLE RIVER AT AVON_NOx",
  "USGS__EAGLE RIVER AT AVON_P", "USGS__EAGLE RIVER AT RED CLIFF_NOx", 
  "USGS__EAGLE RIVER AT RED CLIFF_P", "USGS__EAGLE RIVER NEAR MINTURN_NOx",
  "USGS__EAGLE RIVER NEAR MINTURN_P", "USGS__GORE CREEK AT MOUTH_NOx",
  "USGS__GORE CREEK AT MOUTH_P", "USGS__GORE CREEK UPPER STATION_NOx",
  "USGS__GORE CREEK UPPER STATION_P", "USGS__GREEN RIVER_NOx",
  "USGS__LITTLE RIVER_NOx", "USGS__LITTLE RIVER_P", "USGS__MERCED R_NOx",
  "USGS__YAMPA RIVER AT DEERLODGE PARK_NOx", "USGS__YAMPA RIVER AT DEERLODGE PARK_P",
  # Error in ... << haven't (tried to) identify which function is the one that errors out >>
  ## "Error in if (z) "Reject Ho" else "Do Not Reject Ho" : missing value where TRUE/FALSE needed
  "Catalina Jemez__Marshall Gulch_DSi", "Catalina Jemez__Oracle Ridge_DSi",
  "GRO__Kolyma_DSi", "GRO__Kolyma_NH4", "GRO__Kolyma_NOx",
  "GRO__Lena_DSi", "GRO__Ob_DSi", "GRO__Yenisey_DSi",
  "HBR__ws9_DSi", "Krycklan__Site 1_DSi", "Krycklan__Site 14_DSi", "Krycklan__Site 16_DSi",
  "Krycklan__Site 4_DSi", "Krycklan__Site 5_DSi", "Krycklan__Site 6_DSi", 
  "Krycklan__Site 7_DSi", "LUQ__Q1_DSi", "NIVA__BUSEDRA_DSi",
  "NIVA__FINEALT_DSi", "NIVA__NOREVEF_DSi", "NIVA__ROGEORR_DSi", "NIVA__STREORK_DSi",
  "NIVA__TELESKI_DSi", "NIVA__VAGEOTR_DSi", "NIVA__VESENUM_DSi",
  "NWT__Como Creek_DSi", "Sagehen__Sagehen_DSi", "UMR__BK01.0M_DSi", "UMR__CH00.1M_DSi",
  "UMR__CN00.1M_DSi", "UMR__CU11.6M_DSi", "UMR__I080.2M_DSi", "UMR__LM00.5M_DSi",
  "UMR__M078.0B_DSi", "UMR__M241.4K_DSi", "UMR__M556.4A_DSi", "UMR__M701.1B_DSi",
  "UMR__M764.3A_DSi", "UMR__M786.2C_DSi", "UMR__MQ02.1M_DSi", "UMR__SG16.2C_DSi", "UMR__WP02.6M_DSi",
  "USGS__Cane Creek_DSi", "USGS__OHIO RIVER AT OLMSTED_DSi", "USGS__ROARING FORK_DSi",
  ## Rivers preemptively removed because they are likely to experience this error
  ## I *think* it's a discharge issue which makes all chemicals for a given river fail
  "GRO__Lena_NH4", "GRO__Lena_NOx", "GRO__Ob_NH4", "GRO__Ob_NOx", "GRO__Ob_P",
  "GRO__Yenisey_NH4", "GRO__Yenisey_NOx", "GRO__Yenisey_P",
  "HBR__ws9_NOx", "Krycklan__Site 7_NH4", "Krycklan__Site 7_NO3", "Krycklan__Site 7_P",
  "LUQ__Q1_NH4", "LUQ__Q1_NOx", "LUQ__Q1_P", "NIVA__BUSEDRA_NO3", "NIVA__FINEALT_NO3",
  "NIVA__NOREVEF_NO3", "NIVA__ROGEORR_NH4", "NIVA__ROGEORR_NO3", "NIVA__ROGEORR_P",
  "NIVA__STREORK_NO3", "NIVA__TELESKI_NO3", "NIVA__VAGEOTR_NO3", "NIVA__VESENUM_NO3",
  "Sagehen__Sagehen_NOx", "Sagehen__Sagehen_P", "UMR__BK01.0M_NH4", "UMR__BK01.0M_NOx",
  "UMR__BK01.0M_P", "UMR__CH00.1M_NH4", "UMR__CH00.1M_NOx", "UMR__CH00.1M_P",
  "UMR__CN00.1M_NH4", "UMR__CN00.1M_NOx", "UMR__CN00.1M_P", "UMR__CU11.6M_NH4", 
  "UMR__CU11.6M_NOx", "UMR__CU11.6M_P", "UMR__I080.2M_NH4", "UMR__I080.2M_NOx", 
  "UMR__I080.2M_P", "UMR__LM00.5M_NH4", "UMR__LM00.5M_NOx", "UMR__LM00.5M_P",
  "UMR__M078.0B_NH4", "UMR__M078.0B_NOx", "UMR__M078.0B_P", "UMR__M241.4K_NH4",
  "UMR__M241.4K_NOx", "UMR__M241.4K_P", "UMR__M556.4A_NH4", "UMR__M556.4A_NOx",
  "UMR__M556.4A_P", "UMR__M701.1B_NH4", "UMR__M701.1B_NOx", "UMR__M701.1B_P",
  "UMR__M764.3A_NH4", "UMR__M764.3A_NOx", "UMR__M764.3A_P", "UMR__M786.2C_NH4",
  "UMR__M786.2C_NOx", "UMR__M786.2C_P", "UMR__MQ02.1M_NH4", "UMR__MQ02.1M_NOx",
  "UMR__MQ02.1M_P", "UMR__SG16.2C_NH4", "UMR__SG16.2C_NOx", "UMR__SG16.2C_P",
  "UMR__WP02.6M_NH4", "UMR__WP02.6M_NOx", "UMR__WP02.6M_P", "USGS__OHIO RIVER AT OLMSTED_NH4",
  "USGS__OHIO RIVER AT OLMSTED_NOx", "USGS__OHIO RIVER AT OLMSTED_P", "USGS__ROARING FORK_NH4",
  "USGS__ROARING FORK_NOx", "USGS__ROARING FORK_P"
)

# Identify rivers to do
boot_to_do <- setdiff(x = potential_boots, y = c(done_boots, bad_boot_rivers))
## For quick ID of next few rivers: boot_to_do[1:5]

# Loop across rivers and elements to run WRTDS workflow!
for(river in boot_to_do){
  # for(river in "AND__GSMACK_DSi"){
  
  # Identify corresponding Stream_ID
  stream_id <- chemistry %>%
    dplyr::filter(Stream_Element_ID == river) %>%
    dplyr::select(Stream_ID) %>%
    unique() %>%
    as.character()
  
  # Also element
  element <- chemistry %>%
    dplyr::filter(Stream_Element_ID == river) %>%
    dplyr::select(variable) %>%
    unique() %>%
    as.character()
  
  # Subset chemistry
  river_chem <- chemistry %>%
    dplyr::filter(Stream_Element_ID == river) %>%
    # Drop unneeded columns
    dplyr::select(-Stream_Element_ID, -Stream_ID, -variable)
  
  # Subset discharge to correct river
  river_disc <- discharge %>%
    dplyr::filter(Stream_ID == stream_id) %>%
    dplyr::select(Date, Q)
  
  # Create a common prefix for all outputs from this run of the loop
  out_prefix <- paste0(stream_id, "_", element, "_") 
  
  # Bootstrap - File Exists Check ----
  
  # Message start of loop
  message("Bootstrapping workflow begun for ", element, " at stream '", river, "'")
  
  # Grab start time for processing
  start <- Sys.time()
  
  # Information also subsetted to right river
  river_info <- information %>%
    dplyr::filter(Stream_ID == stream_id) %>%
    # Generate correct information for this element
    dplyr::mutate(constitAbbrev = element) %>%
    dplyr::mutate(paramShortName = dplyr::case_when(
      constitAbbrev == "DSi" ~ "Silicon",
      constitAbbrev == "NOx" ~ "Nitrate",
      constitAbbrev == "P" ~ "Phosphorous",
      constitAbbrev == "NH4" ~ "Ammonium")) %>%
    # Create another needed column
    dplyr::mutate(staAbbrev = shortName) %>%
    # Drop stream ID now that subsetting is complete
    dplyr::select(-Stream_ID)
  
  # Save these as CSVs with generic names
  ## This means each iteration of the loop will overwrite them so this folder won't become gigantic
  write.csv(x = river_disc, row.names = F, na = "",
            file = file.path(path, "WRTDS Temporary Files", "discharge.csv"))
  write.csv(x = river_chem, row.names = F, na = "",
            file = file.path(path, "WRTDS Temporary Files", "chemistry.csv"))
  write.csv(x = river_info, row.names = F, na = "",
            file = file.path(path, "WRTDS Temporary Files", "information.csv"))
  
  # Then read them back in with EGRET's special acquisition functions
  egret_disc <- EGRET::readUserDaily(filePath = file.path(path, "WRTDS Temporary Files"), fileName = "discharge.csv", qUnit = 2, verbose = F)
  egret_chem <- EGRET::readUserSample(filePath = file.path(path, "WRTDS Temporary Files"), fileName = "chemistry.csv", verbose = F)
  egret_info <- EGRET::readUserInfo(filePath = file.path(path, "WRTDS Temporary Files"), fileName = "information.csv", interactive = F)
  
  # Bootstrap - Begin Actual Workflow ----
  
  # Create a list of the discharge, chemistry, and information files
  egret_list <- EGRET::mergeReport(INFO = egret_info, Daily = egret_disc, Sample = egret_chem, verbose = F)
  
  # Run series
  egret_list_out <- EGRET::runSeries(eList = egret_list, windowSide = 11, minNumObs = 50,
                                     verbose = F, windowS = 0.5)
  
  # Handle rivers that have blank time periods
  if(stream_id == "USGS__Mississippi River at Grafton"){
    egret_list_out <- EGRET::blankTime(eList = egret_list_out, startBlank = "1981-10-01", 
                                       endBlank = "1982-09-29") }
  if(stream_id == "USGS__PICEANCE CREEK RYAN GULCH"){
    egret_list_out <- EGRET::blankTime(eList = egret_list_out, startBlank = "1998-10-01",
                                       endBlank = "1999-09-30") }
  if(stream_id == "USGS__YAMPA RIVER AT DEERLODGE PARK"){
    egret_list_out <- EGRET::blankTime(eList = egret_list_out, startBlank = "1994-10-01",
                                       endBlank = "1996-09-30") }
  if(stream_id == "USGS__YUKON RIVER"){
    egret_list_out <- EGRET::blankTime(eList = egret_list_out, startBlank = "1996-10-01",
                                       endBlank = "2001-09-29") }
  
  # Bootstrap - Period of Absence Tweaks ----
  
  # Some rivers just need the period of absence tweaked
  ## McMurdo (12 to 2)
  if(stringr::str_sub(string = stream_id, start = 1, end = 3) == "MCM"){
    egret_list <- EGRET::setPA(eList = egret_list, paStart = 12, paLong = 2)
    egret_list_out <- EGRET::setPA(eList = egret_list_out, paStart = 12, paLong = 2) }
  ## 5 to 5
  if(river %in% unique(pa5_5)){
    egret_list <- EGRET::setPA(eList = egret_list, paStart = 5, paLong = 5)
    egret_list_out <- EGRET::setPA(eList = egret_list_out, paStart = 5, paLong = 5) }
  ## 5 to 3
  if(river %in% unique(pa5_3)){
    egret_list <- EGRET::setPA(eList = egret_list, paStart = 5, paLong = 3)
    egret_list_out <- EGRET::setPA(eList = egret_list_out, paStart = 5, paLong = 3) }
  
  # Run trend estimate for GFN method between start/end years
  egret_pairs <- EGRET::runPairs(eList = egret_list_out, windowSide = 11, minNumObs = 50,
                                 # year1 = min_year,
                                 year1 = min(egret_list_out$Sample$waterYear, na.rm = T),
                                 # year2 = max_year)
                                 year2 = max(egret_list_out$Sample$waterYear, na.rm = T))
  
  # Make a version of that where we have stream and chemical included
  egret_pairs_v2 <- egret_pairs %>%
    dplyr::mutate(Stream_ID = rep(stream_id, times = nrow(egret_pairs)),
                  Solute = rep(element, times = nrow(egret_pairs)),
                  .before = dplyr::everything())
  
  # Export those values as well
  write.csv(x = egret_pairs_v2, row.names = F, na = "",
            file.path(path, "WRTDS Bootstrap Outputs", paste0(out_prefix, "ListPairs_GFN_WRTDS.csv")))
  
  # Estimate trend uncertainty
  egret_boot <- EGRETci::runPairsBoot(eList = egret_list_out, pairResults = egret_pairs, nBoot = 100, blockLength = 200)
  
  # Strip out key results
  egret_boot_results <- data.frame(
    Stream_ID = rep(stream_id, times = length(egret_boot$xConc)),
    Solute = rep(element, times = length(egret_boot$xConc)),
    xConc = egret_boot$xConc,
    xFlux = egret_boot$xFlux,
    pConc = egret_boot$pConc,
    pFlux = egret_boot$pFlux)
  
  # Export the results
  write.csv(x = egret_boot_results, row.names = F, na = "",
            file.path(path, "WRTDS Bootstrap Outputs", paste0(out_prefix, "EGRETCi_GFN_bootstraps.csv")))
  
  # Also grab the summary information
  egret_boot_summary <- as.data.frame(egret_boot$bootOut)
  
  # Add needed information to this one as well
  egret_boot_summary_v2 <- egret_boot_summary %>%
    dplyr::mutate(Stream_ID = rep(stream_id, times = nrow(egret_boot_summary)),
                  Solute = rep(element, times = nrow(egret_boot_summary)),
                  .before = dplyr::everything())
  
  # And export it as well
  write.csv(x = egret_boot_summary_v2, file.path(path, "WRTDS Bootstrap Outputs", paste0(out_prefix, "EGRETCi_GFN_Trend.csv")), row.names = F, na = "")
  
  # Grab the end processing time
  end <- Sys.time()
  
  # Combine timing into a dataframe
  loop_diagnostic <- data.frame("stream" = stream_id,
                                "chemical" = element,
                                "loop_start" = start,
                                "loop_end" = end)
  
  # Export this as well
  write.csv(x = loop_diagnostic, row.names = F, na = "",
            file.path(path, "WRTDS Bootstrap Diagnostic", paste0(out_prefix, "Boot_Loop_Diagnostic.csv")))
  
  # Message completion of loop
  message("Bootstrapping workflow complete for ", element, " at stream '", river, "'")
  
} # End loop

# End ----
